{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n",
    "import glob\n",
    "import sys\n",
    "from dmg.realism.mle import whichFitsBetter\n",
    "from scripts.modelSet import datasets_supported\n",
    "msetObject = datasets_supported['ecore-github']\n",
    "train_path = 'data/ecore-github/train'\n",
    "backend = 'java'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gs = [msetObject.getGraphReal(f,backend) \n",
    "                for f in glob.glob(train_path + \"/*\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomEMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each rule in RandomEMF, depending on the type of rule, we estimate its parameters. More concretely, for shapes we use the function `whichFitsBetter` that selects the best distribuntion by using maximum likeihood. For priorities in alternative rules, the procedure described in the paper is done and it is based on counting each different alternative in the set $R_{II}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Package: EPackage ->\n",
    "    eClassifiers += Classifier#Distribution(parameters);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def isClassifier(tp):\n",
    "    if tp == 'EClass':\n",
    "        return True\n",
    "    if tp == 'EDataType':\n",
    "        return True\n",
    "    if tp == 'EEnum':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "bins = np.arange(0, 200, 5)\n",
    "numberClassifiers = [len([n for n in G if isClassifier(G.nodes[n]['type'])]) for G in Gs]\n",
    "plt.hist(numberClassifiers, bins = bins, alpha=0.5, density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberClassifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportions of classifiers that a package has"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "alter Classifier : EClassifier ->\n",
    "  \tEnum#a | DataType#b |Class#c\n",
    "  ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ps = []\n",
    "for G in Gs:\n",
    "    p = [0, 0, 0]\n",
    "    for n in G[0]:\n",
    "        if (G.nodes[n]['type'] == 'EClass'):\n",
    "            p[0] = p[0] + 1\n",
    "        if (G.nodes[n]['type'] == 'EDataType'):\n",
    "            p[1] = p[1] + 1\n",
    "        if (G.nodes[n]['type'] == 'EEnum'):\n",
    "            p[2] = p[2] + 1\n",
    "    p = np.array(p)\n",
    "    ps.append(p/np.sum(p))\n",
    "ps = np.array(ps)\n",
    "print(np.mean(ps, axis = 0)/np.min(np.mean(ps, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of eliterals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Enum : EEnum ->\n",
    "  \teLiterals += Literal#Distribution(parameters);\n",
    "  ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberEliterals = []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='EEnum':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'eLiterals'):\n",
    "                        cont = cont + 1\n",
    "            numberEliterals.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 50, 1)\n",
    "plt.hist(numberEliterals, bins = bins, alpha=0.5, density = True)\n",
    "\n",
    "print('mean',np.mean(numberEliterals))\n",
    "print('var',np.var(numberEliterals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberEliterals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Structural Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Class: EClass ->\n",
    "    eStructuralFeatures += Feature(self)#Distribution(parameters);\n",
    "  ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberStrctFeat= []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='EClass':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'eStructuralFeatures'):\n",
    "                        cont = cont + 1\n",
    "            numberStrctFeat.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(numberStrctFeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuperTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Class: EClass ->\n",
    "    eSuperTypes +=  Uniform(model.EClassifiers.filter[\n",
    "      it instanceof org.eclipse.emf.ecore.EClass\n",
    "    ].filter[!this.self.EAllSuperTypes.contains(it)].map[it as org.eclipse.emf.ecore.EClass])#Distribution(parameters);\n",
    "  ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superTypes= []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='EClass':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'eSuperTypes'):\n",
    "                        cont = cont + 1\n",
    "                superTypes.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFitsBetter(superTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EAttributes vs EReferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "alter Feature (EClass c): EStructuralFeature ->  \n",
    "     if (model.EClassifiers.filter[it instanceof EDataType].size > 0) Attribute#a |if (model.EClassifiers.filter[it instanceof org.eclipse.emf.ecore.EClass].size > 0)\n",
    "     Reference(c)#b\n",
    "  ;\n",
    "```\n",
    "\n",
    "Estimating `a` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for G in Gs:\n",
    "    p = [0, 0]\n",
    "    for n in G:\n",
    "        if (G.nodes[n]['type'] == 'EAttribute'):\n",
    "            p[0] = p[0] + 1\n",
    "        if (G.nodes[n]['type'] == 'EReference'):\n",
    "            p[1] = p[1] + 1\n",
    "    p = np.array(p)\n",
    "    if (np.sum(p) != 0):\n",
    "        ps.append(p/np.sum(p))\n",
    "    else:\n",
    "        ps.append(p)\n",
    "ps = np.array(ps)\n",
    "print(np.mean(ps, axis = 0)/np.min(np.mean(ps, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EOpposite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rule:\n",
    "\n",
    "``` \n",
    "Reference(EClass c):EReference ->\n",
    "    eOpposite := if (UniformBool(a)) ReferenceOpp(self.EType as EClass,self,c)\n",
    "  ; \n",
    "```\n",
    "\n",
    "Estimating `a` by calculating the proportion of references that contain an opposite one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opposite= []\n",
    "for G in Gs:\n",
    "    for n in G:\n",
    "        if G.nodes[n]['type'] =='EReference':\n",
    "            cont = 0\n",
    "            for e in G[n]:\n",
    "                for e2 in G[n][e]:\n",
    "                     if (G[n][e][e2]['type'] == 'eOpposite'):\n",
    "                        cont = cont + 1\n",
    "                opposite.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([n for n in opposite if n == 1])/len(opposite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
