{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import dmg.model2graph.model2graph as m2g\n",
    "import dmg.model2graph.metafilter as mf\n",
    "from networkx.algorithms.isomorphism import is_isomorphic\n",
    "import dmg.graphUtils as gu\n",
    "import glob\n",
    "import dmg.ecore.ecorePallete as ecore\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metafilter_refs = ['EClass.eSuperTypes',\n",
    "                          'EClassifier.ePackage',\n",
    "                           'EPackage.eClassifiers',\n",
    "                           'ETypedElement.eType',\n",
    "                           'EStructuralFeature.eContainingClass',\n",
    "                           'EReference.eOpposite',\n",
    "                           'EEnum.eLiterals',\n",
    "                           'EEnumLiteral.eEnum',\n",
    "                           'EClass.eStructuralFeatures']\n",
    "metafilter_cla = ['EClass', 'EPackage', 'EDataType',\n",
    "                         'EStructuralFeature','EEnum', 'EEnumLiteral']   \n",
    "metafilter_atts = None\n",
    "metafilterobj = mf.MetaFilter(references = metafilter_refs, \n",
    "                 attributes = metafilter_atts,\n",
    "                 classes = metafilter_cla)       \n",
    "meta_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/ecoreDataset/train/*\")\n",
    "graphs = []\n",
    "for f in files:\n",
    "    graphs.append(m2g.getGraphFromModel(f, \n",
    "                                  meta_models, metafilterobj,\n",
    "                                  consider_atts = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of graphs:', len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/ecoreDataset/val/*\")\n",
    "graphs_val = []\n",
    "for f in files:\n",
    "    graphs_val.append(m2g.getGraphFromModel(f, \n",
    "                                  meta_models, metafilterobj,\n",
    "                                  consider_atts = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of graphs:', len(graphs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecore.ecore_pallete.shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from dmg.deeplearning.dataGeneration import sequence2data, data2graph\n",
    "from dmg.deeplearning.dataGeneration import addInvEdges\n",
    "\n",
    "listDatas_val = []\n",
    "batch_size = 64\n",
    "max_len = 2\n",
    "print('Preparing seqs')\n",
    "for g in graphs_val:\n",
    "    sequence = ecore.ecore_pallete.graphToSequence(g)\n",
    "    sequence = [(addInvEdges(s[0], ecore.ecore_pallete, ecore.ecore_separator),s[1]) for s in sequence]\n",
    "    listDatas_val = listDatas_val + sequence2data(sequence, ecore.ecore_pallete, max_len)\n",
    "loader_val = DataLoader(listDatas_val, batch_size=batch_size, \n",
    "                        num_workers = 0, \n",
    "                        shuffle=False)\n",
    "print('Seqs finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_eval = False\n",
    "\n",
    "if not do_eval:\n",
    "    graphs = graphs + graphs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of graphs:', len(graphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dmg.deeplearning.generativeModel import GenerativeModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import multiprocess as mp\n",
    "\n",
    "def f(g):\n",
    "    sequence = ecore.ecore_pallete.graphToSequence(g)\n",
    "    sequence = [(addInvEdges(s[0], ecore.ecore_pallete, ecore.ecore_separator),s[1]) for s in sequence]\n",
    "    return sequence2data(sequence, ecore.ecore_pallete, max_len)\n",
    "\n",
    "epochs = 100\n",
    "hidden_dim = 128\n",
    "\n",
    "\n",
    "criterion_node = nn.CrossEntropyLoss(reduction = 'mean',ignore_index=-1)\n",
    "criterion_action = nn.CrossEntropyLoss(reduction = 'mean')\n",
    "criterion_finish = nn.BCELoss(reduction = 'mean')\n",
    "model = GenerativeModel(hidden_dim, ecore.dic_nodes_ecore, ecore.dic_edges_ecore, ecore.dic_operations_ecore)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    listDatas = []\n",
    "    #preparing training set\n",
    "    print('Preparing seqs')\n",
    "    with mp.Pool(10) as pool:\n",
    "        listDatas = pool.map(f, graphs)\n",
    "    listDatas = [r for rr in listDatas for r in rr]\n",
    "    print('Seqs finished')\n",
    "    loader = DataLoader(listDatas, batch_size=batch_size, \n",
    "                            num_workers = 0, \n",
    "                            shuffle=False)\n",
    "    #training\n",
    "    for data in loader:\n",
    "        opt.zero_grad()\n",
    "        action, nodes, finish = model(data.x, data.edge_index, \n",
    "                        torch.squeeze(data.edge_attr,dim=1), \n",
    "                data.batch, data.sequence, data.nodes, data.len_seq, data.action)\n",
    "        \n",
    "        nodes = torch.unsqueeze(nodes, dim = 2).repeat(1,1,2)\n",
    "        nodes[:,:,0] = 1 - nodes[:,:,1]\n",
    "            \n",
    "        L = torch.max(data.len_seq).item()\n",
    "        gTruth = data.sequence_masked[:,0:L]\n",
    "        loss = (criterion_node(nodes.reshape(-1,2), gTruth.flatten()) +\n",
    "                    criterion_action(action, data.action) +\n",
    "                    criterion_finish(finish.flatten(), data.finished.float())) / 3\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    #validation\n",
    "    if do_eval:\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in loader_val:\n",
    "                action, nodes, finish = model(data.x, data.edge_index, \n",
    "                            torch.squeeze(data.edge_attr,dim=1), \n",
    "                    data.batch, data.sequence, data.nodes, data.len_seq, data.action)\n",
    "                nodes = torch.unsqueeze(nodes, dim = 2).repeat(1,1,2)\n",
    "                nodes[:,:,0] = 1 - nodes[:,:,1]\n",
    "\n",
    "                L = torch.max(data.len_seq).item()\n",
    "                gTruth = data.sequence_masked[:,0:L]\n",
    "                loss = (criterion_node(nodes.reshape(-1,2), gTruth.flatten()) +\n",
    "                        criterion_action(action, data.action) +\n",
    "                        criterion_finish(finish.flatten(), data.finished.float())) / 3\n",
    "                val_loss+= loss.item()\n",
    "        \n",
    "    print('Epoch',epoch,'Loss Traning',total_loss/(len(loader)))\n",
    "    #scheduler.step()\n",
    "    if do_eval:\n",
    "        print('Epoch',epoch,'Loss Val',val_loss/(len(loader_val)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/ecoreDataset/test/*\")\n",
    "graphs_test = []\n",
    "for f in files:\n",
    "    graphs_test.append(m2g.getGraphFromModel(f, \n",
    "                                  meta_models, metafilterobj,\n",
    "                                  consider_atts = False))\n",
    "print('Number of graphs:', len(graphs_test))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmg.deeplearning.generativeModel import sampleGraph\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "samples = [sampleGraph(ecore.G_initial_ecore_1, ecore.ecore_pallete, model,\n",
    "                       np.max([len(g) for g in graphs]), ecore.ecore_separator) \n",
    "           for i in range(len(graphs_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot([len(G) for G in samples], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([len(G) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dmg.realism.metrics as mt\n",
    "sns.distplot([np.mean(mt.getListDegree(G)) for G in samples], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([np.mean(mt.getListDegree(G)) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = list(ecore.dic_edges_ecore.keys())\n",
    "sns.distplot([np.mean(list(mt.MPC(G,dims).values())) for G in samples], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([np.mean(list(mt.MPC(G,dims).values())) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check isomorf and consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h = plt.hist([len(G) for G in samples], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist([len(G) for G in graphs], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check isomorf\n",
    "iso = []\n",
    "for s in samples:\n",
    "    for g in graphs:\n",
    "        if (is_isomorphic(s,g,gu.node_match_type, gu.edge_match_type)):\n",
    "            iso.append(s)\n",
    "            break\n",
    "print(len(iso)*100/len(samples),'% iso')\n",
    "not_iso = [g for g in samples if not g in iso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x=[len(G) for G in iso])\n",
    "print('Mean size:', np.mean([len(G) for G in iso]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmg.ecore.ecoreConsistency import inconsistent\n",
    "#check consistency\n",
    "inconsistents = []\n",
    "for s in samples:\n",
    "    if inconsistent(s):\n",
    "        inconsistents.append(s)\n",
    "print(len(inconsistents)*100/len(samples),'% inconsistents')\n",
    "not_inconsistents = [g for g in samples if not g in inconsistents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=[len(G) for G in inconsistents])\n",
    "print('Mean size:', np.mean([len(G) for G in inconsistents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_new_models = [g for g in not_iso if not g in inconsistents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=[len(G) for G in clean_new_models])\n",
    "print('Mean size:', np.mean([len(G) for G in clean_new_models]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=[len(G) for G in graphs])\n",
    "print('Mean size:', np.mean([len(G) for G in graphs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clean_new_models),'clean models')\n",
    "print(len(clean_new_models)*100/len(samples),'% clean models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot([len(G) for G in clean_new_models], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([len(G) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([np.mean(mt.getListDegree(G)) for G in clean_new_models], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([np.mean(mt.getListDegree(G)) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = list(ecore.dic_edges_ecore.keys())\n",
    "sns.distplot([np.mean(list(mt.MPC(G,dims).values())) for G in clean_new_models], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([np.mean(list(mt.MPC(G,dims).values())) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot([len(G) for G in not_inconsistents], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([len(G) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot([np.mean(mt.getListDegree(G)) for G in not_inconsistents], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([np.mean(mt.getListDegree(G)) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = list(ecore.dic_edges_ecore.keys())\n",
    "sns.distplot([np.mean(list(mt.MPC(G,dims).values())) for G in not_inconsistents], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([np.mean(list(mt.MPC(G,dims).values())) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realism using GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from dmg.deeplearning.dataGeneration import generateTensorsFromGraph\n",
    "syns = []\n",
    "sett = clean_new_models#samples\n",
    "for G in random.sample(sett,min(len(sett),len(graphs_test))):\n",
    "    G_inv = addInvEdges(G, ecore.ecore_pallete, ecore.ecore_separator)\n",
    "    tensors = generateTensorsFromGraph(G_inv, ecore.ecore_pallete, 2, 2)\n",
    "    data =  Data(x = tensors[0],\n",
    "                edge_index = tensors[-2], \n",
    "                edge_attr = tensors[-1],\n",
    "                y = torch.tensor(0))\n",
    "    syns.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reals = []\n",
    "#graphs_test = [g for g in graphs_test if len(g.edges) >= 1]\n",
    "for G in random.sample(graphs_test,min(len(sett),len(graphs_test))):\n",
    "    G_inv = addInvEdges(G, ecore.ecore_pallete, ecore.ecore_separator)\n",
    "    tensors = generateTensorsFromGraph(G_inv, ecore.ecore_pallete, 2, 2)\n",
    "    data =  Data(x = tensors[0],\n",
    "                edge_index = tensors[-2], \n",
    "                edge_attr = tensors[-1],\n",
    "                y = torch.tensor(1))\n",
    "    reals.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = syns + reals\n",
    "random.shuffle(dataset)\n",
    "print('Len train:', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "train_len = int(0.8*len(dataset))\n",
    "test_len = len(dataset) - int(0.8*len(dataset))\n",
    "train, test = random_split(dataset, [train_len, test_len], \n",
    "                                generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=32, num_workers = 5, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=1, num_workers = 5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from dmg.realism.discriminativeModel import DiscriminativeModel\n",
    "\n",
    "model = DiscriminativeModel(64,64,0.0,ecore.dic_nodes_ecore,ecore.dic_edges_ecore).cpu()\n",
    "\n",
    "epochs = 30\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    b = 1\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        pred = model(data.x.cpu(), data.edge_index.cpu(),\n",
    "          torch.squeeze(data.edge_attr.cpu(),dim=1),data.batch.cpu())\n",
    "        \n",
    "        loss = criterion(torch.squeeze(pred), data.y.float().cpu())\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        b = b + 1\n",
    "        \n",
    "    print('Epoch',e,'Loss',total_loss/b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "count = 0\n",
    "i0 = 0\n",
    "i1 = 0\n",
    "for data in test_loader:\n",
    "    pred = model(data.x.cpu(), data.edge_index.cpu(),\n",
    "          torch.squeeze(data.edge_attr,dim=1).cpu(),data.batch.cpu())\n",
    "    if pred[0].item() > 0.5:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    if pred == data.y.long().item():\n",
    "        count = count + 1\n",
    "    \n",
    "print('Acc', count/len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "def C2ST_pvalue(acc,n_test):\n",
    "    return st.norm.cdf(-(acc-0.5)/(math.sqrt(1/(4*n_test))))\n",
    "\n",
    "print('p-value', C2ST_pvalue(count/len(test_loader),len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a sample of clean models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dot = gu.plotGraphViz(random.sample(clean_new_models,1)[0])\n",
    "dot.format = 'pdf'\n",
    "dot.view(filename='example', directory='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m2g.getModelFromGraph(['../data/metamodels/yakinduSimplified.ecore'], clean_new_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2g.serializeGraphModel('example.xmi',['../data/metamodels/yakinduSimplified.ecore'], 'Statechart', clean_new_models[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
