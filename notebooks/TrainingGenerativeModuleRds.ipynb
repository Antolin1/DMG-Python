{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import dmg.model2graph.model2graph as m2g\n",
    "import dmg.model2graph.metafilter as mf\n",
    "from networkx.algorithms.isomorphism import is_isomorphic\n",
    "import dmg.graphUtils as gu\n",
    "import glob\n",
    "import dmg.rds.rdsPallete as rds\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metafilter_refs = ['Database.elements', \n",
    "                           'Table.indexes',\n",
    "                           'Table.columns',\n",
    "                           'Index.indexColumns',\n",
    "                           'IndexColumn.column',\n",
    "                           'Reference.primaryKeyColumns',\n",
    "                           'Reference.foreignKeyColumns',\n",
    "                           'Column.primaryReferences',\n",
    "                           'Column.foreignReferences']\n",
    "metafilter_cla = ['Database', 'Column','Table',\n",
    "                          'Index', 'IndexColumn','Reference']  \n",
    "metafilter_atts = None\n",
    "metafilterobj = mf.MetaFilter(references = metafilter_refs, \n",
    "                     attributes = metafilter_atts,\n",
    "                     classes = metafilter_cla)\n",
    "meta_models = ['../data/metamodels/rds_manual.ecore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/rdsDataset/train/*\")\n",
    "graphs = []\n",
    "for f in files:\n",
    "    graphs.append(m2g.getGraphFromModel(f, \n",
    "                              meta_models, metafilterobj,\n",
    "                              consider_atts = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 362\n"
     ]
    }
   ],
   "source": [
    "print('Number of graphs:', len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/rdsDataset/val/*\")\n",
    "graphs_val = []\n",
    "for f in files:\n",
    "    graphs_val.append(m2g.getGraphFromModel(f, \n",
    "                              meta_models, metafilterobj,\n",
    "                              consider_atts = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 122\n"
     ]
    }
   ],
   "source": [
    "print('Number of graphs:', len(graphs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing seqs\n",
      "Seqs finished\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from dmg.deeplearning.dataGeneration import sequence2data, data2graph\n",
    "\n",
    "listDatas_val = []\n",
    "batch_size = 64\n",
    "max_len = 3\n",
    "print('Preparing seqs')\n",
    "for g in graphs_val:\n",
    "    sequence = rds.rds_pallete.graphToSequence(g)\n",
    "    if len(sequence[-1][0].edges()) == 0:\n",
    "        continue\n",
    "    listDatas_val = listDatas_val + sequence2data(sequence, rds.rds_pallete, max_len)\n",
    "loader_val = DataLoader(listDatas_val, batch_size=batch_size, \n",
    "                        num_workers = 0, \n",
    "                        shuffle=False)\n",
    "print('Seqs finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_eval = False\n",
    "\n",
    "if not do_eval:\n",
    "    graphs = graphs + graphs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 484\n"
     ]
    }
   ],
   "source": [
    "print('Number of graphs:', len(graphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing seqs\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\multiprocess\\pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-21-ee344cb55d74>\", line 13, in f\n  File \"..\\dmg\\deeplearning\\dataGeneration.py\", line 75, in sequence2data\n    nT, sN, sNM, edges, edges_lab = generateTensorsFromGraph(G,\n  File \"..\\dmg\\deeplearning\\dataGeneration.py\", line 45, in generateTensorsFromGraph\n    torch.transpose(torch.tensor(edges), 0, 1),\nIndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-ee344cb55d74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m#    listDatas = listDatas + sequence2data(sequence, yp.yakindu_pallete, max_len)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mlistDatas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mlistDatas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistDatas\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrr\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Seqs finished'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\multiprocess\\pool.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         '''\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\multiprocess\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "from dmg.deeplearning.generativeModel import GenerativeModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import multiprocess as mp\n",
    "\n",
    "def f(g):\n",
    "    import dmg.rds.rdsPallete as rds\n",
    "    from dmg.deeplearning.dataGeneration import sequence2data\n",
    "    max_len = 3\n",
    "    sequence = rds.rds_pallete.graphToSequence(g)\n",
    "    if sequence[-1][0].edges()==0:\n",
    "        return None\n",
    "    return sequence2data(sequence, rds.rds_pallete, max_len)\n",
    "\n",
    "epochs = 100\n",
    "hidden_dim = 128\n",
    "\n",
    "\n",
    "criterion_node = nn.CrossEntropyLoss(reduction = 'mean',ignore_index=-1)\n",
    "criterion_action = nn.CrossEntropyLoss(reduction = 'mean')\n",
    "criterion_finish = nn.BCELoss(reduction = 'mean')\n",
    "model = GenerativeModel(hidden_dim, rds.dic_nodes_rds, rds.dic_edges_rds, rds.dic_operations_rds)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    listDatas = []\n",
    "    #preparing training set\n",
    "    print('Preparing seqs')\n",
    "    #for g in graphs:\n",
    "    #    sequence = yp.yakindu_pallete.graphToSequence(g)\n",
    "    #    listDatas = listDatas + sequence2data(sequence, yp.yakindu_pallete, max_len)\n",
    "    with mp.Pool(5) as pool:\n",
    "        listDatas = pool.map(f, graphs)\n",
    "    listDatas = [r for rr in listDatas if rr != None for r in rr]\n",
    "    print('Seqs finished')\n",
    "    loader = DataLoader(listDatas, batch_size=batch_size, \n",
    "                            num_workers = 0, \n",
    "                            shuffle=False)\n",
    "    #training\n",
    "    for data in loader:\n",
    "        opt.zero_grad()\n",
    "        action, nodes, finish = model(data.x, data.edge_index, \n",
    "                        torch.squeeze(data.edge_attr,dim=1), \n",
    "                data.batch, data.sequence, data.nodes, data.len_seq, data.action)\n",
    "        \n",
    "        nodes = torch.unsqueeze(nodes, dim = 2).repeat(1,1,2)\n",
    "        nodes[:,:,0] = 1 - nodes[:,:,1]\n",
    "            \n",
    "        L = torch.max(data.len_seq).item()\n",
    "        gTruth = data.sequence_masked[:,0:L]\n",
    "        loss = (criterion_node(nodes.reshape(-1,2), gTruth.flatten()) +\n",
    "                    criterion_action(action, data.action) +\n",
    "                    criterion_finish(finish.flatten(), data.finished.float())) / 3\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    #validation\n",
    "    if do_eval:\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in loader_val:\n",
    "                action, nodes, finish = model(data.x, data.edge_index, \n",
    "                            torch.squeeze(data.edge_attr,dim=1), \n",
    "                    data.batch, data.sequence, data.nodes, data.len_seq, data.action)\n",
    "                nodes = torch.unsqueeze(nodes, dim = 2).repeat(1,1,2)\n",
    "                nodes[:,:,0] = 1 - nodes[:,:,1]\n",
    "\n",
    "                L = torch.max(data.len_seq).item()\n",
    "                gTruth = data.sequence_masked[:,0:L]\n",
    "                loss = (criterion_node(nodes.reshape(-1,2), gTruth.flatten()) +\n",
    "                        criterion_action(action, data.action) +\n",
    "                        criterion_finish(finish.flatten(), data.finished.float())) / 3\n",
    "                val_loss+= loss.item()\n",
    "        \n",
    "    print('Epoch',epoch,'Loss Traning',total_loss/(len(loader)))\n",
    "    #scheduler.step()\n",
    "    if do_eval:\n",
    "        print('Epoch',epoch,'Loss Val',val_loss/(len(loader_val)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/yakinduDataset/test/*\")\n",
    "graphs_test = []\n",
    "for f in files:\n",
    "    graphs_test.append(m2g.getGraphFromModel(f, \n",
    "                              meta_models, metafilterobj,\n",
    "                              consider_atts = False))\n",
    "print('Number of graphs:', len(graphs_test))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmg.deeplearning.generativeModel import sampleGraph\n",
    "\n",
    "model.eval()\n",
    "samples = [sampleGraph(yp.G_initial_yak, yp.yakindu_pallete, model, 50) for i in range(len(graphs_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot([len(G) for G in samples], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([len(G) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dmg.realism.metrics as mt\n",
    "sns.distplot([np.mean(mt.getListDegree(G)) for G in samples], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([np.mean(mt.getListDegree(G)) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = list(yp.dic_edges_yak.keys())\n",
    "sns.distplot([np.mean(list(mt.MPC(G,dims).values())) for G in samples], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', label = 'NN')\n",
    "sns.distplot([np.mean(list(mt.MPC(G,dims).values())) for G in graphs_test], hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'blue', label = 'Real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check isomorf and consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "h = plt.hist([len(G) for G in samples], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist([len(G) for G in graphs], bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check isomorf\n",
    "iso = []\n",
    "for s in samples:\n",
    "    for g in graphs:\n",
    "        if (is_isomorphic(s,g,gu.node_match_type, gu.edge_match_type)):\n",
    "            iso.append(s)\n",
    "            break\n",
    "print(len(iso)*100/len(samples),'% iso')\n",
    "not_iso = [g for g in samples if not g in iso]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x=[len(G) for G in iso])\n",
    "print('Mean size:', np.mean([len(G) for G in iso]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dmg.yakindu.yakinduConsistency import inconsistent\n",
    "#check consistency\n",
    "inconsistents = []\n",
    "for s in samples:\n",
    "    if inconsistent(s):\n",
    "        inconsistents.append(s)\n",
    "print(len(inconsistents)*100/len(samples),'% inconsistents')\n",
    "not_inconsistents = [g for g in samples if not g in inconsistents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=[len(G) for G in inconsistents])\n",
    "print('Mean size:', np.mean([len(G) for G in inconsistents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_new_models = [g for g in not_iso if not g in inconsistents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=[len(G) for G in clean_new_models])\n",
    "print('Mean size:', np.mean([len(G) for G in clean_new_models]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=[len(G) for G in graphs])\n",
    "print('Mean size:', np.mean([len(G) for G in graphs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(clean_new_models),'clean models')\n",
    "print(len(clean_new_models)*100/len(samples),'% clean models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a sample of clean models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dot = gu.plotGraphViz(random.sample(clean_new_models,1)[0])\n",
    "dot.format = 'pdf'\n",
    "dot.view(filename='example', directory='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m2g.getModelFromGraph(['../data/metamodels/yakinduSimplified.ecore'], clean_new_models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2g.serializeGraphModel('example.xmi',['../data/metamodels/yakinduSimplified.ecore'], 'Statechart', clean_new_models[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
